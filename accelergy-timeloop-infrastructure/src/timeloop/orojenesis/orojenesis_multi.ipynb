{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1acd029",
   "metadata": {},
   "source": [
    "# Orojenesis Artifact - Multi-Einsum\n",
    "\n",
    "The ipython notebook file contains calls to Orojenesis to reproduce results in the ISCA'24 *\"Mind the Gap: Attainable Data Movement and Operational Intensity Bounds for Tensor Algorithms\"* paper. Note that there are minor differences compared to the plots shown in the paper due to bug fixes. We will update the plots in the camera ready version. \n",
    "\n",
    "## 0.  Setup Software Dependencies \n",
    " Please first run install.sh to install software dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe86710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if \"TIMELOOP_BASE_PATH\" not in os.environ:\n",
    "    timeloop_path = input(\"Please specify the path to Timeloop repo (default: \" +  os.getcwd() + \"/../):\" ) or os.getcwd() + \"/../\"\n",
    "    os.environ[\"TIMELOOP_BASE_PATH\"] = timeloop_path\n",
    "os.environ[\"TIMELOOP_ENABLE_FIRST_READ_ELISION\"] = \"1\"\n",
    "print('Path to timeloop repo: ', os.environ[\"TIMELOOP_BASE_PATH\"])\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import src.utils as utils\n",
    "import src.plots as plots\n",
    "import matplotlib.pyplot as plt\n",
    "import src.gen_mappings as gen_mappings\n",
    "import src.process_untiled_fusion as process_untiled_fusion\n",
    "import src.process_tiled_fusion as process_tiled_fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93796d",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Generate Multi-Einsum Data Movement Bounds\n",
    "\n",
    "The following experiments generate the data movement bounds for multi-einsums with 1) baseline unfused mappings, 2) untiled fusion, and 3) tiled fusion. \n",
    "\n",
    "1) **Baseline Unfused Mapping:**\n",
    "    * Each einsum executes sequentially without fusion.\n",
    "    * Intra-layer mapspace remains fully unconstrained.\n",
    "    * Once single-einsum pareto-optimal data movement bounds are generated, we sum up the achievable data movement at different buffer size constraints to compose the multi-einsum bounds.\n",
    "2) **Untiled Fusion:**\n",
    "    * Intra-layer mapspace is still unconstrained.\n",
    "    * Fusion assumes full buffering of intermediate output tensors.\n",
    "    * Multi-einsum data movement bounds are constructed by:\n",
    "        * Subtracting intermediate accesses from overall data movement.\n",
    "        * Adding intermediate output sizes to buffer requirements for each einsum to enable fusion.\n",
    "3) **Tiled Fusion w/ FFMT:**\n",
    "    * FFMT (Fusion Friendly Mapping Template) described in the paper is applied to each einsum.\n",
    "    * Fusion only requires buffering of a subtile of the intermediate outputs.    \n",
    "    * Multi-einsum data movement bounds is contructed such that:\n",
    "        * The data movement for all intermediate outputs is saved.\n",
    "        * The buffer size requirement is the maximal buffer utilization of all einsums.   \n",
    "Single-einsum bounds are generated with different contraints mentioned above using the single-einsum *Orojenesis* flow in `orojenesis_single.ipynb`.\n",
    "\n",
    "First, we specify the workload directory that stores the multi-einsum workload specification, Orojenesis configuration directory that stores the speeder architecture specs, and the output directory for storing the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workload_dir = pathlib.Path('./workloads')\n",
    "config_dir = pathlib.Path('./configs/multi-einsum')\n",
    "output_dir = pathlib.Path('./outputs/multi-einsum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77b616",
   "metadata": {},
   "source": [
    "### Run Orojenesis search to generate bounds  (Estimated Runtime: 2 hours) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Einsum Mapping Search for GPT-6.7b in Fig.18, 21-23. \n",
    "# It will take roughly 2 hours to finish all experiments on a 4-core Intel® Core™i7-1185G7 processor @ 3.00 GHz.\n",
    "model_name = 'gpt3-6.7b'\n",
    "batch_size = 16\n",
    "num_heads = 32\n",
    "arch_prefix = ''\n",
    "force_rerun = False\n",
    "\n",
    "\n",
    "# Generate baseline optimal unconstrained unfused mappings.\n",
    "gen_mappings.gen_mappings(workload_dir, config_dir, output_dir, \\\n",
    "                            model_name=model_name, batch=batch_size, num_heads=num_heads, spatial_factor=None, arch_prefix=arch_prefix, ffmt=False, force_rerun=force_rerun)\n",
    "\n",
    "# Generate mappings following fusion friendly mapping templates (FFMT)\n",
    "gen_mappings.gen_mappings(workload_dir, config_dir, output_dir, \\\n",
    "                          model_name=model_name, batch=batch_size, num_heads=num_heads, spatial_factor=None, arch_prefix=arch_prefix, ffmt=True, force_rerun=force_rerun)\n",
    "\n",
    "\n",
    "# For six-layer chain\n",
    "# Generate the unfused, and untiled fusion bounds\n",
    "process_untiled_fusion.process_untiled_fusion(workload_dir, output_dir, model_name=model_name, \\\n",
    "                                              input_format='chain', num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, matmul_only=False)\n",
    "\n",
    "# w/o flashattn mapspace\n",
    "# Generate the tiled fusion bounds\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', \\\n",
    "                                          num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix)\n",
    "# Generate the tiled fusion bounds for segmented chains\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', \\\n",
    "                                          num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, eval_slices=True)\n",
    "\n",
    "# w/ flashattn mapspace\n",
    "# Generate the tiled fusion bounds\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', \\\n",
    "                                          num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, constraint_config='_relax_io_kn_flash')\n",
    "# Generate the tiled fusion bounds for segmented chains\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', \\\n",
    "                                          num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, eval_slices=True, constraint_config='_relax_io_kn_flash')\n",
    "\n",
    "# For full LLM block schedule\n",
    "# Generate the unfused, and untiled fusion bounds\n",
    "process_untiled_fusion.process_untiled_fusion(workload_dir, output_dir, model_name=model_name, \\\n",
    "                                              input_format='opt_schedules_mm', num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, matmul_only=False)\n",
    "# Generate the tiled fusion bounds\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, \\\n",
    "                                          input_format='opt_schedules_mm', num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix)\n",
    "# Generate the tiled fusion bounds for segmented chains\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, \\\n",
    "                                          input_format='opt_schedules_mm', num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, eval_slices=True)\n",
    "# Generate the tiled fusion bounds for segmented chains w/ flashattn\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, \\\n",
    "                                          input_format='opt_schedules_mm', num_heads=num_heads, batch=batch_size, arch_prefix=arch_prefix, eval_slices=True, constraint_config='_relax_io_kn_flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9310be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Einsum Mapping Search for MHA in Fig.20. \n",
    "# It will take roughly 5 minutes to finish all experiments on a 4-core Intel® Core™i7-1185G7 processor.\n",
    "model_name = \"attn-block\"\n",
    "batch_size = 16\n",
    "num_heads = 32\n",
    "force_rerun = False\n",
    "\n",
    "gen_mappings.gen_mappings(workload_dir, config_dir, output_dir, model_name=model_name, batch=batch_size, num_heads=num_heads, spatial_factor=None, arch_prefix='', ffmt=False, force_rerun=force_rerun)\n",
    "gen_mappings.gen_mappings(workload_dir, config_dir, output_dir, model_name=model_name, batch=batch_size, num_heads=num_heads, spatial_factor=None, arch_prefix='', ffmt=True, force_rerun=force_rerun)\n",
    "\n",
    "process_untiled_fusion.process_untiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', num_heads=num_heads, batch=batch_size, matmul_only=False)\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', num_heads=num_heads, batch=batch_size)\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', num_heads=num_heads, batch=batch_size, constraint_config='_relax_io')\n",
    "process_tiled_fusion.process_tiled_fusion(workload_dir, output_dir, model_name=model_name, input_format='chain', num_heads=num_heads, batch=batch_size, constraint_config='_flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa615070",
   "metadata": {},
   "source": [
    "## 2. Plot Multi-Einsum Bounds\n",
    "We save the generated figures under `fig_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e410d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = pathlib.Path('./figs')\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313583fb",
   "metadata": {},
   "source": [
    "## Fig.18: Backing-store bounds for 32kx4kx16k and 32kx16kx4k GEMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt3-6.7b'\n",
    "batch_size=16\n",
    "num_heads=32\n",
    "input_format='chain'\n",
    "\n",
    "# Get workload chain specs\n",
    "chains, layers_dict, _ = utils.get_chain_config(workload_dir, output_dir, model_name=model_name, \n",
    "                                                    input_format=input_format, num_heads=num_heads, batch_size=batch_size)\n",
    "\n",
    "for chain_idx, chain in enumerate(chains):\n",
    "    print(f'chain {chain_idx}: {chain}')\n",
    "    \n",
    "# Calculate theoretical optimal bounds \n",
    "optimal_accesses, optimal_accesses_fused = plots.get_optimal_performance(chains, layers_dict, num_heads)\n",
    "\n",
    "# FFN is the 4th chain in the gpt3-6.7b workload \n",
    "chain_idx = 4 \n",
    "\n",
    "# Get path name to different bounds \n",
    "csv_tiled_fusion = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size)\n",
    "csv_unfused = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='', scheme='opt', num_heads=num_heads, batch_size=batch_size, enable_fusion=False, matmul_only=False)\n",
    "csv_untiled_fusion = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='', scheme='opt', num_heads=num_heads, batch_size=batch_size)\n",
    "csv_tiled_fusion_flash = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size, constraint_config='_relax_io_kn_flash')\n",
    "\n",
    "# Load bounds to pandas dataframe \n",
    "df_tiled_fusion =  pd.read_csv(csv_tiled_fusion)      \n",
    "df_unfused = pd.read_csv(csv_unfused)\n",
    "df_untiled_fusion = pd.read_csv(csv_untiled_fusion)\n",
    "df_tiled_fusion_flash = pd.read_csv(csv_tiled_fusion_flash)\n",
    "\n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion, 'Tiled Fusion'), optimal_accesses[chain_idx], \\\n",
    "                                    optimal_accesses_fused[chain_idx],  figsize=(2.5,2.5), \\\n",
    "                                    df_nochain=(df_unfused, 'No Fusion'), \\\n",
    "                                    df_nochain_fused=(df_untiled_fusion, 'Untiled Fusion'), \\\n",
    "#                                     df_relax_io=(df_tiled_fusion_flash, 'Tiled Fusion Flash'), \\\n",
    "                                    xbound=(10**3, 2*10**9), ybound=(None, 8*10**11), max_effect_size=None)\n",
    "legend = ax.legend(loc='upper center', bbox_to_anchor=(0.6, 1), fontsize=8)\n",
    "plt.savefig(f\"{fig_dir}/fig18a.pdf\", format=\"pdf\", bbox_inches=\"tight\")   \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the reduction stats of the tiled fusion and unfused bounds\n",
    "df_red = utils.compute_reduction(df_unfused, df_tiled_fusion)\n",
    "fig, ax = plt.subplots(dpi=300, figsize=(2.5, 2.5))\n",
    "plt.ylabel('Reduction Factor \\n (No fusion / Tiled fusion)')        \n",
    "line = ax.axhline(y=1, color='black', linestyle='-', lw=1, label='SOL w/o fusion')\n",
    "df_red.set_index('max_buf_size').sort_index()['accesses_ratio'].plot(ax=ax, logx=True, xlim=(10**3, 10**9))\n",
    "plt.xlabel('Buffer Size (B)')\n",
    "plt.savefig(f\"{fig_dir}/fig18b.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d13649",
   "metadata": {},
   "source": [
    "## Fig.20: Backing-store bounds for different multi-head attention (MHA) fusion strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f64535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input graph definition chain\n",
    "model_name = 'attn-block'\n",
    "batch_size=16\n",
    "num_heads=32\n",
    "input_format='chain'\n",
    "\n",
    "# Get workload chain specs\n",
    "chains, layers_dict, _ = utils.get_chain_config(workload_dir, output_dir, model_name=model_name, \n",
    "                                                    input_format=input_format, num_heads=num_heads, batch_size=batch_size)\n",
    "\n",
    "# Calculate theoretical optimal bounds \n",
    "optimal_accesses, optimal_accesses_fused = plots.get_optimal_performance(chains, layers_dict, num_heads, batch_size)\n",
    "print(f'Data reduction: {optimal_accesses[0]/optimal_accesses_fused[0]}')\n",
    "\n",
    "# MHA is the 0th chain\n",
    "chain_idx = 0\n",
    "\n",
    "# Get path name to different bounds \n",
    "csv_tiled_fusion_kn = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size)\n",
    "csv_tiled_fusion_n = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='_relax_io', num_heads=num_heads, batch_size=batch_size)\n",
    "csv_tiled_fusion_flash = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='_flash', num_heads=num_heads, batch_size=batch_size)\n",
    "csv_unfused = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='', scheme='opt', num_heads=num_heads, batch_size=batch_size, enable_fusion=False, matmul_only=False)\n",
    "\n",
    "df_tiled_fusion_kn = pd.read_csv(csv_tiled_fusion_kn)\n",
    "df_tiled_fusion_n = pd.read_csv(csv_tiled_fusion_n)\n",
    "df_tiled_fusion_flash = pd.read_csv(csv_tiled_fusion_flash)\n",
    "df_unfused = pd.read_csv(csv_unfused)\n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion_flash, 'FlashAttention'), optimal_accesses[chain_idx], optimal_accesses_fused[chain_idx], \n",
    "                                    df_nochain=(df_unfused, 'No Fusion'), df_relax_io=(df_tiled_fusion_n, 'FLAT'), \n",
    "                                    figsize=(5*2.5/3,2.5), xbound=(10**2, None), ybound=(None, None)) # (df_tiled_fusion_kn, 'tileKN')\n",
    "legend = ax.legend(loc='upper left', ncol=3, fontsize=8)\n",
    "plt.savefig(f\"{fig_dir}/fig20.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5bcf6",
   "metadata": {},
   "source": [
    "### Fig.21: Backing-store bounds for fusing six GEMMs in LLMs block with optimal segmentation stategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63057638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'gpt3-6.7b'\n",
    "batch_size=16\n",
    "num_heads=32\n",
    "input_format='chain'\n",
    "arch_prefix=''\n",
    "\n",
    "# Get workload chain specs\n",
    "chains, layers_dict, _ = utils.get_chain_config(workload_dir, output_dir, model_name=model_name, \n",
    "                                                    input_format=input_format, num_heads=num_heads, batch_size=batch_size)\n",
    "# Calculate theoretical optimal bounds \n",
    "optimal_accesses, optimal_accesses_fused = plots.get_optimal_performance(chains, layers_dict, num_heads, batch_size)\n",
    "\n",
    "# 6 GEMMs is the 0th chain in the gpt3-6.7b workload \n",
    "chain_idx = 0\n",
    "\n",
    "# Get path name to different bounds \n",
    "csv_tiled_fusion = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                   num_heads=num_heads, batch_size=batch_size, arch_prefix=arch_prefix)\n",
    "csv_unfused = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='', scheme='opt', num_heads=num_heads, batch_size=batch_size,\n",
    "                                         arch_prefix=arch_prefix, enable_fusion=False, matmul_only=False)\n",
    "csv_tiled_segmented_fusion = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size, arch_prefix=arch_prefix, eval_slices=True)\n",
    "csv_tiled_segmented_fusion_flash = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size, arch_prefix=arch_prefix, eval_slices=True,\n",
    "                                                   constraint_config='_relax_io_kn_flash')\n",
    "\n",
    "df_tiled_fusion =  pd.read_csv(csv_tiled_fusion)      \n",
    "df_unfused = pd.read_csv(csv_unfused)\n",
    "df_tiled_segmented_fusion = pd.read_csv(csv_tiled_segmented_fusion)\n",
    "df_tiled_segmented_fusion_flash = pd.read_csv(csv_tiled_segmented_fusion_flash)\n",
    "\n",
    "df_csv = df_tiled_segmented_fusion_flash[[\"max_buf_size\", \"fused_accesses\", \"slice\", \"mapping\"]]\n",
    "df_csv.to_csv(f'{model_name}_b{batch_size}_fused.csv')\n",
    "\n",
    "# log-scale\n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion, 'Tiled Fusion'), optimal_accesses[chain_idx], optimal_accesses_fused[chain_idx], \n",
    "                                    figsize=(5*2.5/3,3*2.5/3), logx=True, logy=True, df_nochain=(df_tiled_segmented_fusion, 'No Fusion'), \n",
    "                                    xbound=(10**3, None), ybound=(None, None), \n",
    "                                    df_slice=(df_tiled_segmented_fusion_flash, 'Segmented Tiled Fusion'), max_effect_size=True) # (df_tiled_segmented_fusion, 'Segmented Tiled Fusion')\n",
    "legend = ax.legend(loc='upper center', ncol=2, columnspacing=1, fontsize=8)\n",
    "\n",
    "# log-scale\n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion, 'Tiled Fusion'), optimal_accesses[chain_idx], optimal_accesses_fused[chain_idx], \n",
    "                                    figsize=(6*2.5/3,3*2.5/3), logx=True, logy=True, df_nochain=(df_tiled_segmented_fusion, 'No Fusion'), \n",
    "                                    xbound=(10**3, None), ybound=(None, None), max_effect_size=True) # (df_tiled_segmented_fusion, 'Segmented Tiled Fusion')\n",
    "legend = ax.legend(loc='upper center', ncol=2, columnspacing=1, fontsize=8)\n",
    "\n",
    "# linear-scale \n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion, 'Tiled Fusion'), optimal_accesses[chain_idx], optimal_accesses_fused[chain_idx], \n",
    "                                    figsize=(5*2.5/3,3*2.5/3), logx=False, logy=False, df_nochain=(df_unfused, 'No Fusion'), xbound=(10**6, None), ybound=(0, 10*10**10), \n",
    "                                    df_slice=(df_tiled_segmented_fusion_flash, 'Segmented Tiled Fusion'), max_effect_size=False) # (df_tiled_segmented_fusion, 'Segmented Tiled Fusion')\n",
    "legend = ax.legend(loc='upper center', ncol=2, columnspacing=1, fontsize=8)\n",
    " \n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion, 'Tiled Fusion'), optimal_accesses[chain_idx], optimal_accesses_fused[chain_idx], \n",
    "                                    figsize=(8*2.5/3,2*2.5/3), logx=False, logy=False, df_nochain=None, xbound=(1**6, None), ybound=(0, 1*10**10), \n",
    "                                    df_slice=(df_tiled_segmented_fusion_flash, 'Segmented Tiled Fusion'), max_effect_size=False) # (df_tiled_segmented_fusion, 'Segmented Tiled Fusion')\n",
    "\n",
    "legend = ax.legend(loc='upper center', ncol=2, columnspacing=1, fontsize=8)\n",
    "plt.savefig(\"figs/fig21.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1b411",
   "metadata": {},
   "source": [
    "## Fig.22: Backing-store bounds for scheduling all GEMMs in an LLMs block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt3-6.7b'\n",
    "batch_size=16\n",
    "num_heads=32\n",
    "input_format='opt_schedules_mm'\n",
    "\n",
    "# Get workload chain specs\n",
    "chains, layers_dict, _ = utils.get_chain_config(workload_dir, output_dir, model_name=model_name, \n",
    "                                                    input_format=input_format, num_heads=num_heads, batch_size=batch_size)\n",
    "# Calculate theoretical optimal bounds \n",
    "optimal_accesses, optimal_accesses_fused = plots.get_optimal_performance(chains, layers_dict, num_heads)\n",
    "\n",
    "# 6 GEMMs is the 0th chain in the gpt3-6.7b workload \n",
    "chain_idx = 0\n",
    "\n",
    "# Get path name to different bounds \n",
    "csv_tiled_fusion = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                   num_heads=num_heads, batch_size=batch_size)\n",
    "csv_unfused = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='', scheme='opt', num_heads=num_heads, batch_size=batch_size, enable_fusion=False,  matmul_only=False)\n",
    "csv_tiled_segmented_fusion = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size, eval_slices=True)\n",
    "csv_tiled_segmented_fusion_flash = utils.get_output_path(chain_idx, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size, eval_slices=True, constraint_config='_relax_io_kn_flash')\n",
    "\n",
    "df_tiled_fusion =  pd.read_csv(csv_tiled_fusion)      \n",
    "df_unfused = pd.read_csv(csv_unfused)\n",
    "df_tiled_segmented_fusion = pd.read_csv(csv_tiled_segmented_fusion)\n",
    "df_tiled_segmented_fusion_flash = pd.read_csv(csv_tiled_segmented_fusion_flash)\n",
    "\n",
    "ax = plots.plot_accesses_comparison((df_tiled_fusion, 'Tiled Fusion'), optimal_accesses[chain_idx], optimal_accesses_fused[chain_idx], \n",
    "                                    figsize=(5*2.5/3,2.5), df_nochain=(df_unfused, 'No Fusion'), xbound=(10**6, 5*10**8), ybound=(None, 10**11), \n",
    "                                    df_slice=(df_tiled_segmented_fusion_flash, 'Segmented Tiled Fusion'), max_effect_size=True, y_max_effectual=0.001,\n",
    "                                    x_algo_min_unfused=3, x_algo_min_fused=3, plot_cache=['L2'])\n",
    "legend = ax.legend(loc='upper center', ncol=2, columnspacing=1, fontsize=8)\n",
    "plt.savefig(\"figs/fig22.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "min_accesses = df_tiled_fusion['fused_accesses'].min()\n",
    "print(f'Optimal data movement reduction: {optimal_accesses[chain_idx]  / min_accesses}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ba007",
   "metadata": {},
   "source": [
    "## 3. Bounds for Provisioning Buffer to Compute Area Ratios\n",
    "\n",
    "This section demonstrates how Orojenesis bounds can be leveraged to determine the optimal ratio between buffer area and MAC operation area within a chip design. We consider a scenario with a fixed total chip area. As an example, we'll use the area and technology details of the GF100 chip (40nm) with the Orojenesis bounds generated for the gpt3-6.7b LLM block above.  \n",
    "\n",
    "## Fig.23: Hardware design tradeoff for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Arch specs \n",
    "area_per_mac = 332.25  # um^2\n",
    "area_per_B = 2.59122   # um^2\n",
    "chip_area = 529*10**6 # um^2\n",
    "freq = 0.7 * 10**9     # GHz\n",
    "bw_Bps=147.8*10**9     # B/s\n",
    "\n",
    "total_area = chip_area * 0.8 # um^2, we assume 80% of chip area is dedicated to the MAC and buffer\n",
    "total_compute=14399012077568.0 # MACs\n",
    "\n",
    "# Workload specs \n",
    "model_name = 'gpt3-6.7b'\n",
    "batch_size=16\n",
    "num_heads=32\n",
    "input_format='opt_schedules_mm'\n",
    "\n",
    "# Get path name to different bounds \n",
    "csv_untiled = utils.get_output_path(0, output_dir, model_name, input_format=input_format, \n",
    "                                         constraint_config='', scheme='opt', num_heads=num_heads, batch_size=batch_size, enable_fusion=False)\n",
    "csv_tiled_segmented_fusion = utils.get_output_path(0, output_dir, model_name, input_format=input_format, \n",
    "                                         num_heads=num_heads, batch_size=batch_size, eval_slices=True, constraint_config='_relax_io_kn_flash')\n",
    "df_untiled = pd.read_csv(csv_untiled)\n",
    "df_tiled_segmented_fusion = pd.read_csv(csv_tiled_segmented_fusion)\n",
    "\n",
    "# Note that please the previous cell before running this one \n",
    "mem_bound_perf, compute_bound_perf, perf, buf_ratio, intersection = utils.derive_performance_bounds(df_untiled, area_per_mac, area_per_B, freq, bw_Bps, total_area, total_compute)\n",
    "print(max(perf))\n",
    "plots.plot_buf_area_tradeoff(mem_bound_perf, compute_bound_perf, perf, buf_ratio, intersection, area_per_B, total_area, plot_offset=-0.36, figname='design_llm_unfused')\n",
    "\n",
    "mem_bound_perf, compute_bound_perf, perf, buf_ratio, intersection = utils.derive_performance_bounds(df_tiled_segmented_fusion, area_per_mac, area_per_B, freq,  bw_Bps, total_area, total_compute)\n",
    "print(max(perf))\n",
    "plots.plot_buf_area_tradeoff(mem_bound_perf, compute_bound_perf, perf, buf_ratio, intersection, area_per_B, total_area, plot_offset=0.02, figname='design_llm_fused')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
